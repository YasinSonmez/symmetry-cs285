{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cef1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import d3rlpy\n",
    "from d3rlpy.algos import COMBO\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import gymnasium as gym\n",
    "import gym\n",
    "from gym.wrappers import TransformObservation\n",
    "import numpy as np\n",
    "import encoders\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75d409c5-cac8-4777-9379-9e8425842246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n",
      "2.2.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(gym.version.VERSION)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5f2b7-f1c9-4c90-b9ff-a0991612c559",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6547464d-8f48-46fd-b606-f121a3cd53f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.23643249,   9.00927393, -22.35811053,   8.97298894,\n",
       "        -3.76337096,  -4.81754121])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1\n",
    "d3rlpy.seed(seed)\n",
    "use_gpu = True\n",
    "# prepare environment\n",
    "#env = gym.make(\"InvertedPendulum-v2\")\n",
    "#eval_env = gym.make(\"InvertedPendulum-v2\")\n",
    "# env = gym.make(\"Reacher-v2\")\n",
    "# eval_env = gym.make(\"Reacher-v2\")\n",
    "env = environments.CarEnv()\n",
    "eval_env = environments.CarEnv()\n",
    "env.reset(seed=seed)\n",
    "eval_env.reset(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "440451b1-8676-4661-bc2e-857e94586cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def observation_edit1(obs):\n",
    "#     new_obs = np.zeros(6)\n",
    "#     new_obs[0] = np.arctan2(obs[2], obs[0])\n",
    "#     new_obs[1] = np.arctan2(obs[3], obs[1])\n",
    "#     new_obs[2:] = obs[4:-3]\n",
    "#     return new_obs\n",
    "\n",
    "# env1 = TransformObservation(env, observation_edit1)\n",
    "# env1.observation_space = gym.spaces.Box(-np.inf, np.inf, shape=(6,), dtype= np.float64 )\n",
    "# print(env1.reset(seed=seed))\n",
    "\n",
    "# eval_env1 = TransformObservation(eval_env, observation_edit1)\n",
    "# eval_env1.observation_space = gym.spaces.Box(-np.inf, np.inf, shape=(6,), dtype= np.float64 )\n",
    "# print(env1.reset(seed=seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35492fa-eb11-45b6-b1bc-50b9d9893ab5",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "133dc7a7-22c1-4bc8-a90c-9ebcce88928a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:49:51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/exp_test_car_SAC_2024-02-15_20240215154951\u001b[0m\n",
      "\u001b[2m2024-02-15 15:49:51\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding model...             \u001b[0m\n",
      "\u001b[2m2024-02-15 15:49:51\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModel has been built.         \u001b[0m\n",
      "\u001b[2m2024-02-15 15:49:51\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters are saved to d3rlpy_logs/exp_test_car_SAC_2024-02-15_20240215154951/params.json\u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'action_scaler': None, 'actor_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': 0.2}}, 'actor_learning_rate': 0.0003, 'actor_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'batch_size': 256, 'critic_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'critic_learning_rate': 0.0003, 'critic_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'gamma': 0.99, 'generated_maxlen': 100000, 'initial_temperature': 1.0, 'n_critics': 2, 'n_frames': 1, 'n_steps': 1, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'real_ratio': 1.0, 'reward_scaler': None, 'scaler': None, 'tau': 0.005, 'temp_learning_rate': 0.0003, 'temp_optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'use_gpu': 0, 'algorithm': 'SAC', 'observation_shape': (6,), 'action_size': 4}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed52ed62c4ce479ebb51c668f429d702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:49:52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mexp_test_car_SAC_2024-02-15_20240215154951: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 0.0011125824451446533, 'time_environment_step': 6.556248664855956e-05, 'rollout_return': 1.7298613990474887e-30, 'time_step': 0.0012606935501098633, 'evaluation': 2.1809515445946591e-72}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m buffer \u001b[38;5;241m=\u001b[39m d3rlpy\u001b[38;5;241m.\u001b[39monline\u001b[38;5;241m.\u001b[39mbuffers\u001b[38;5;241m.\u001b[39mReplayBuffer(maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, env\u001b[38;5;241m=\u001b[39menv)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# start training\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43msac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_online\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_start_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensorboard_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensorboard_logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexp_test_car_SAC_2024-02-15\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Berkeley/Fa23/cs285/final_project/symmetry-cs285/d3rlpy/d3rlpy/algos/base.py:251\u001b[0m, in \u001b[0;36mAlgoBase.fit_online\u001b[0;34m(self, env, buffer, explorer, n_steps, n_steps_per_epoch, update_interval, update_start_step, random_steps, eval_env, eval_epsilon, save_metrics, save_interval, experiment_name, with_timestamp, logdir, verbose, show_progress, tensorboard_dir, timelimit_aware, callback)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# check action-space\u001b[39;00m\n\u001b[1;32m    249\u001b[0m _assert_action_space(\u001b[38;5;28mself\u001b[39m, env)\n\u001b[0;32m--> 251\u001b[0m \u001b[43mtrain_single_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_start_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_start_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_epsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_timestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_timestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensorboard_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimelimit_aware\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimelimit_aware\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Berkeley/Fa23/cs285/final_project/symmetry-cs285/d3rlpy/d3rlpy/online/iterators.py:264\u001b[0m, in \u001b[0;36mtrain_single_env\u001b[0;34m(algo, env, buffer, explorer, n_steps, n_steps_per_epoch, update_interval, update_start_step, random_steps, eval_env, eval_epsilon, save_metrics, save_interval, experiment_name, with_timestamp, logdir, verbose, show_progress, tensorboard_dir, timelimit_aware, callback)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# update parameters\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mmeasure_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm_update\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 264\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# record metrics\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/Berkeley/Fa23/cs285/final_project/symmetry-cs285/d3rlpy/d3rlpy/base.py:748\u001b[0m, in \u001b[0;36mLearnableBase.update\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: TransitionMiniBatch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    739\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update parameters with mini-batch of data.\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \n\u001b[1;32m    741\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m \n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grad_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documents/Berkeley/Fa23/cs285/final_project/symmetry-cs285/d3rlpy/d3rlpy/algos/sac.py:202\u001b[0m, in \u001b[0;36mSAC._update\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# lagrangian parameter update for SAC temperature\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temp_learning_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 202\u001b[0m     temp_loss, temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_temp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: temp_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m\"\u001b[39m: temp})\n\u001b[1;32m    205\u001b[0m critic_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl\u001b[38;5;241m.\u001b[39mupdate_critic(batch)\n",
      "File \u001b[0;32m~/Documents/Berkeley/Fa23/cs285/final_project/symmetry-cs285/d3rlpy/d3rlpy/torch_utility.py:313\u001b[0m, in \u001b[0;36mtrain_api.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    312\u001b[0m     set_train_mode(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Berkeley/Fa23/cs285/final_project/symmetry-cs285/d3rlpy/d3rlpy/torch_utility.py:260\u001b[0m, in \u001b[0;36mtorch_api.<locals>._torch_api.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, TransitionMiniBatch):\n\u001b[0;32m--> 260\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mTorchMiniBatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_scaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreward_scaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreward_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    269\u001b[0m         data\u001b[38;5;241m=\u001b[39mval,\n\u001b[1;32m    270\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m    271\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    272\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Berkeley/Fa23/cs285/final_project/symmetry-cs285/d3rlpy/d3rlpy/torch_utility.py:172\u001b[0m, in \u001b[0;36mTorchMiniBatch.__init__\u001b[0;34m(self, batch, device, scaler, action_scaler, reward_scaler)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    164\u001b[0m     batch: TransitionMiniBatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m ):\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# convert numpy array to torch tensor\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     observations \u001b[38;5;241m=\u001b[39m _convert_to_torch(batch\u001b[38;5;241m.\u001b[39mobservations, device)\n\u001b[0;32m--> 172\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_to_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m _convert_to_torch(batch\u001b[38;5;241m.\u001b[39mrewards, device)\n\u001b[1;32m    174\u001b[0m     next_observations \u001b[38;5;241m=\u001b[39m _convert_to_torch(batch\u001b[38;5;241m.\u001b[39mnext_observations, device)\n",
      "File \u001b[0;32m~/Documents/Berkeley/Fa23/cs285/final_project/symmetry-cs285/d3rlpy/d3rlpy/torch_utility.py:148\u001b[0m, in \u001b[0;36m_convert_to_torch\u001b[0;34m(array, device)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_torch\u001b[39m(array: np\u001b[38;5;241m.\u001b[39mndarray, device: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    147\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m--> 148\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actor_encoder = d3rlpy.models.encoders.DefaultEncoderFactory(dropout_rate=0.2)\n",
    "# setup algorithm\n",
    "sac = d3rlpy.algos.SAC(\n",
    "    batch_size=256,\n",
    "    actor_encoder_factory=actor_encoder,\n",
    "    actor_learning_rate=3e-4,\n",
    "    critic_learning_rate=3e-4,\n",
    "    temp_learning_rate=3e-4,\n",
    "    use_gpu=use_gpu\n",
    ")\n",
    "\n",
    "# prepare utilities\n",
    "buffer = d3rlpy.online.buffers.ReplayBuffer(maxlen=10000, env=env)\n",
    "\n",
    "# start training\n",
    "sac.fit_online(\n",
    "    env,\n",
    "    buffer,\n",
    "    eval_env=eval_env,\n",
    "    n_steps=10000,\n",
    "    n_steps_per_epoch=1000,\n",
    "    update_interval=1,\n",
    "    update_start_step=1000,\n",
    "    tensorboard_dir='tensorboard_logs',\n",
    "    experiment_name='exp_test_car_SAC_2024-02-15',\n",
    "    save_interval=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e7bd2-1bdf-4dec-9ecc-d1b42275b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export replay buffer as MDPDataset\n",
    "dataset = buffer.to_mdp_dataset()\n",
    "\n",
    "# save MDPDataset\n",
    "dataset.dump('d3rlpy_data/car_test_2024-02-15.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4fca6-103e-4428-8afe-04f98213ed31",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e3d33-fceb-4576-a2da-5f617d746d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = d3rlpy.dataset.MDPDataset.load('d3rlpy_data/car_test_2024-02-15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e58c8-a0ea-42a0-825a-702e5fa767be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes, test_episodes = train_test_split(dataset, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425935b5-2a2f-497d-a63e-c2eb7f7cf8eb",
   "metadata": {},
   "source": [
    "## Dynamics learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610f1a8-8f9a-497b-b172-fcffd5245056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inverted_pendulum_project(x):\n",
    "#     return x[:, 1:]\n",
    "# projection_size = 3\n",
    "\n",
    "# def reacher_project(x):\n",
    "#     # return x[:, [1,4,5]]\n",
    "    \n",
    "projector = env.preprocess_fn\n",
    "projection_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db25ae-3d57-4680-bec9-9ccde0b9f983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SymmetryEncoderFactory\n"
     ]
    }
   ],
   "source": [
    "encoder_factory = encoders.SymmetryEncoderFactory(project=projector, projection_size=projection_size)\n",
    "dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics(learning_rate=1e-4, use_gpu=True, state_encoder_factory=encoder_factory)\n",
    "#dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics(learning_rate=1e-4, use_gpu=True) # Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6a23e36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:08\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mRoundIterator is selected.    \u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/car_2024-02-15_20240215155008\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:08\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/params.json\u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'action_scaler': None, 'augmentation': None, 'batch_size': 100, 'discrete_action': False, 'gamma': 1.0, 'generated_maxlen': 100000, 'learning_rate': 0.0001, 'n_ensembles': 5, 'n_frames': 1, 'n_steps': 1, 'optim_factory': {'optim_cls': 'Adam', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}, 'permutation_indices': None, 'real_ratio': 1.0, 'reduction': None, 'reward_encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'reward_scaler': None, 'scaler': None, 'state_encoder_factory': {'type': 'symmetry', 'params': {'hidden_units': [256, 256], 'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None, 'use_dense': False, 'project': <function CarEnv.preprocess_fn at 0x7f9778a35af0>, 'projection_size': 3}}, 'use_gpu': 0, 'variance_type': 'max', 'algorithm': 'ProbabilisticEnsembleDynamics', 'observation_shape': (6,), 'action_size': 4}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319bb2a0ed6549c089282141ab57bf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=1 step=75\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00026103019714355467, 'time_algorithm_update': 0.024373235702514647, 'loss': 34.58080952962239, 'time_step': 0.024705158869425457}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m75\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_75.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4b8d7ef8fc4b7dafb92bdebc30bdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=2 step=150\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00023705482482910156, 'time_algorithm_update': 0.022897698084513345, 'loss': 33.87072738647461, 'time_step': 0.023211046854654947}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m150\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_150.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fa9ac44de74843b748891b9176d277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=3 step=225\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0002469762166341146, 'time_algorithm_update': 0.023074671427408853, 'loss': 34.09314628601074, 'time_step': 0.02339872678120931}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m225\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_225.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627870328cf14cc888c10d5c3d61cfe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=4 step=300\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00023389180501302083, 'time_algorithm_update': 0.023121477762858073, 'loss': 34.50152109781901, 'time_step': 0.023424596786499025}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m300\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_300.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77d7ff83a14439c8c7067dba38a2e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=5 step=375\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00023855845133463542, 'time_algorithm_update': 0.023003495534261068, 'loss': 34.22541206359863, 'time_step': 0.023321520487467447}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m375\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_375.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3f77c5fb61428ea294cddf142928f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=6 step=450\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0002520593007405599, 'time_algorithm_update': 0.02361097017923991, 'loss': 34.089635365804035, 'time_step': 0.023941415150960287}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m450\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_450.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d00c96bed094201a7a68e28b5e5f210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=7 step=525\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m7\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00025441805521647133, 'time_algorithm_update': 0.02392187436421712, 'loss': 33.74408271789551, 'time_step': 0.024257097244262695}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m525\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_525.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2d5354ba094c94a1d5303a3b6624e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=8 step=600\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m8\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0002584743499755859, 'time_algorithm_update': 0.02519740104675293, 'loss': 33.40949851989746, 'time_step': 0.025526192982991535}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m600\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_600.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75290c035ed414f9b7bd7dec9d36a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=9 step=675\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m9\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00024956385294596354, 'time_algorithm_update': 0.023643817901611328, 'loss': 33.373305079142256, 'time_step': 0.023970244725545247}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m675\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_675.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf8cea275c2470aa5625becd2dd37b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-02-15 15:50:27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mcar_2024-02-15_20240215155008: epoch=10 step=750\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m10\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00025678316752115885, 'time_algorithm_update': 0.02393456776936849, 'loss': 33.99833318074544, 'time_step': 0.024277162551879884}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m750\u001b[0m\n",
      "\u001b[2m2024-02-15 15:50:27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/car_2024-02-15_20240215155008/model_750.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bd5b2500e74bc6837086367a60b2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/100:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same as algorithms\n",
    "dynamics.fit(train_episodes,\n",
    "             eval_episodes=test_episodes,\n",
    "            #  n_epochs=100,\n",
    "            n_steps=100000,\n",
    "             n_steps_per_epoch=1000,\n",
    "             scorers={\n",
    "               #  'observation_error': d3rlpy.metrics.scorer.dynamics_observation_prediction_error_scorer,\n",
    "               #  'reward_error': d3rlpy.metrics.scorer .dynamics_reward_prediction_error_scorer,\n",
    "               #  'variance': d3rlpy.metrics.scorer.dynamics_prediction_variance_scorer,\n",
    "             },\n",
    "            tensorboard_dir='tensorboard_logs/test',\n",
    "            experiment_name='car_2024-02-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce29e5-ef7b-4ae1-a5b1-0098a1ccb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_dynamics_training(dataset, symmetry_project, projection_size, n_runs, experiment_name, seed=1, use_gpu=True):\n",
    "    for i in range(n_runs):\n",
    "        for exp_type in ['default', 'symmetry']:\n",
    "            # use the same seeds for default and symmetric runs\n",
    "            train_episodes, test_episodes = train_test_split(dataset, random_state=seed+i)\n",
    "            if exp_type == 'symmetry':\n",
    "                state_encoder_factory = encoders.SymmetryEncoderFactory(project=symmetry_project, projection_size=projection_size)\n",
    "                train_episodes, test_episodes = train_test_split(dataset, random_state=seed+i+1) # remove this later\n",
    "                dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics(learning_rate=1e-4, use_gpu=use_gpu, state_encoder_factory=state_encoder_factory)\n",
    "            else:\n",
    "                dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics(learning_rate=1e-4, use_gpu=use_gpu)\n",
    "            dynamics.fit(train_episodes,\n",
    "                 eval_episodes=test_episodes,\n",
    "                 n_epochs=100,\n",
    "                 scorers={\n",
    "                    'observation_error': d3rlpy.metrics.scorer.dynamics_observation_prediction_error_scorer,\n",
    "                    'reward_error': d3rlpy.metrics.scorer.dynamics_reward_prediction_error_scorer,\n",
    "                    'variance': d3rlpy.metrics.scorer.dynamics_prediction_variance_scorer,\n",
    "                 },\n",
    "                tensorboard_dir='tensorboard_logs/dynamics',\n",
    "                experiment_name=experiment_name + '_' + exp_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f779639-e088-4def-bdc8-ccfec3ef74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dynamics_training(dataset=dataset, symmetry_project=reacher_project, projection_size=3, n_runs=5, experiment_name=\"exp_5_dynamics_reacher\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a0377-82fa-4d78-b498-0bcdd282fc51",
   "metadata": {},
   "source": [
    "## Load Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2da5d-f176-42d6-b72e-e94800db8db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained dynamics model\n",
    "dynamics_model_path = \"d3rlpy_logs/ProbabilisticEnsembleDynamics_20231002230632\"\n",
    "dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics.from_json(dynamics_model_path + '/params.json')\n",
    "dynamics.load_model(dynamics_model_path + '/model_31542.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd5232-3ff4-44cc-afb8-a0cf2038071d",
   "metadata": {},
   "source": [
    "## Train Offline RL Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5e387-db4f-4499-8d94-d74fbdfa75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = d3rlpy.models.encoders.DefaultEncoderFactory(dropout_rate=0.2)\n",
    "# give COMBO as the generator argument.\n",
    "combo = COMBO(dynamics=dynamics, critic_encoder_factory=encoder, actor_encoder_factory=encoder,\n",
    "              use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67116a4e-3e12-4f9b-a639-cd52b508761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.fit(dataset = train_episodes, eval_episodes=test_episodes, n_steps=100000, n_steps_per_epoch=1000, tensorboard_dir=\"tensorboard_logs\",\n",
    "         scorers={\n",
    "            'environment': d3rlpy.metrics.scorer.evaluate_on_environment(eval_env)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427da29-d0b1-4566-b44d-b0c8e0952012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_COMBO_training(dataset, eval_env, experiment_name, save_name, models_dir, symmetry_project, projection_size, seed=1, use_gpu=True):\n",
    "    model_paths = [filename for filename in os.listdir(models_dir) if filename.startswith(experiment_name+'_dynamics')]\n",
    "    model_paths = [models_dir + model_paths_i for model_paths_i in model_paths]\n",
    "    model_paths.sort()\n",
    "    print(model_paths)\n",
    "\n",
    "    symmetry_reduced_paths = []\n",
    "    default_paths = []\n",
    "    for model_path_i in model_paths:\n",
    "        f = open(model_path_i +'/params.json')\n",
    "        model_path_i_params = json.load(f)\n",
    "        if(model_path_i_params[\"state_encoder_factory\"]['type']=='symmetry'):\n",
    "            symmetry_reduced_paths.append(model_path_i)\n",
    "        elif(model_path_i_params[\"state_encoder_factory\"]['type']=='default'):\n",
    "            default_paths.append(model_path_i)\n",
    "    print(\"Default_paths:\", default_paths, \"Symmetry reduced paths: \", symmetry_reduced_paths)\n",
    "\n",
    "    # load trained dynamics model\n",
    "    for i in range(len(default_paths)):\n",
    "        for type, dynamics_model_path in zip(['symmetry', 'default'],[symmetry_reduced_paths[i], default_paths[i]]):\n",
    "            # use the same seeds for default and symmetric runs\n",
    "            train_episodes, test_episodes = train_test_split(dataset, random_state=seed+i)\n",
    "            if type == 'symmetry':\n",
    "                state_encoder_factory = encoders.SymmetryEncoderFactory(project=symmetry_project, projection_size=projection_size)\n",
    "                dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics(learning_rate=1e-4, use_gpu=use_gpu, state_encoder_factory=state_encoder_factory)\n",
    "                dynamics.build_with_dataset(dataset)\n",
    "            else:\n",
    "                dynamics = d3rlpy.dynamics.ProbabilisticEnsembleDynamics.from_json(dynamics_model_path + '/params.json')\n",
    "\n",
    "            filenames = os.listdir(dynamics_model_path)\n",
    "            latest_model_path = dynamics_model_path + '/model_' +  str(max([int(filename.strip('model_.pt')) for filename in filenames if filename.endswith(\".pt\")])) + '.pt'\n",
    "            dynamics.load_model(latest_model_path)\n",
    "            print(\"Loaded model: \", latest_model_path)\n",
    "            \n",
    "            encoder = d3rlpy.models.encoders.DefaultEncoderFactory(dropout_rate=0.2)\n",
    "            # give COMBO as the generator argument.\n",
    "            combo = COMBO(dynamics=dynamics, critic_encoder_factory=encoder, actor_encoder_factory=encoder, use_gpu=use_gpu)\n",
    "            combo.fit(dataset = train_episodes, eval_episodes=test_episodes, n_steps=1000000, n_steps_per_epoch=1000,\n",
    "                      tensorboard_dir=\"tensorboard_logs\",\n",
    "                     scorers={\n",
    "                        'environment': d3rlpy.metrics.scorer.evaluate_on_environment(eval_env)\n",
    "                    },\n",
    "                     experiment_name=save_name + \"_\" + type,\n",
    "                     save_interval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62117ddd-609b-43eb-9bfc-bef02c1c0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_COMBO_training(dataset, eval_env1, 'exp_5', save_name='exp_5_COMBO_reacher', models_dir='d3rlpy_logs/', symmetry_project=reacher_project, projection_size=3, seed=1, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975eb780-5bf9-4dce-a157-2a3391301db6",
   "metadata": {},
   "source": [
    "## Load the Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e723b-9836-489a-b6de-d66d7cf6dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actor_encoder = d3rlpy.models.encoders.DefaultEncoderFactory(dropout_rate=0.2)\n",
    "# setup algorithm\n",
    "trained_policy = d3rlpy.algos.SAC()\n",
    "trained_policy.build_with_env(env1)\n",
    "trained_policy.load_model('d3rlpy_logs/exp_6_SAC_reacher_20231024124119/model_100000.pt')\n",
    "\n",
    "# initialize with dataset\n",
    "#trained_policy.build_with_dataset(dataset)\n",
    "# Load entire model parameters.\n",
    "#trained_policy.load_model('d3rlpy_logs/COMBO_20230929153035/model_53000.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b5477-7e6c-4701-a2f3-a0df1f357aa1",
   "metadata": {},
   "source": [
    "## See the policy running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e69dd-55a6-4c4b-a2a3-fe66e4626a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = d3rlpy.metrics.scorer.evaluate_on_environment(env1, render=True)\n",
    "mean_episode_return = scorer(trained_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cda57-eebb-494e-a58b-6fd6abfb31c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
